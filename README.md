# Solutions for Generative AI with Large Language Models (LLMs) Labs

Welcome to my repository of solutions for the lab exercises from the DeepLearning.AI course, **Generative AI with Large Language Models (LLMs)**. This repository contains my implementations for the hands-on labs provided in the course.

## Course Overview

In this course, we explore the principles of generative AI with a focus on LLMs, covering topics from model pre-training and fine-tuning to reinforcement learning and application deployment. Here’s a quick overview of what the course covers:

- **Generative AI Fundamentals**
- **Transformer Architecture**
- **Scaling Laws**
- **Fine-tuning and Evaluation**
- **Reinforcement Learning and Applications**

## Lab Solutions

### Week 1: Generative AI Use Cases, Project Lifecycle, and Model Pre-training

- **Lab 1: Summarize Dialogue Use Case**
  - **Description:** Implementation of a dialogue summarization model using generative AI techniques.
  - **File:** 
    - `Lab_1_summarize_dialogue.ipynb`: Jupyter notebook containing code for preprocessing data, training the model, and evaluating its performance.

### Week 2: Fine-tuning and Evaluating Large Language Models

- **Lab 2: Fine-tune a Generative AI Model for Dialogue Summarization**
  - **Description:** Solution for fine-tuning an LLM on dialogue summarization tasks.
  - **File:** 
    - `Lab_2_fine_tune_generative_ai_model.ipynb`: Jupyter notebook with code for applying Parameter-efficient Fine Tuning (PEFT) and evaluating the model's performance.

### Week 3: Reinforcement Learning and LLM-powered Applications

- **Lab 3: Fine-tune a Model to Detoxify Summaries**
  - **Description:** Implementation details for fine-tuning a model using reinforcement learning from human feedback (RLHF) to generate more positive summaries.
  - **File:** 
    - `Lab_3_fine_tune_model_to_detoxify_summaries.ipynb`: Jupyter notebook containing code for training with RLHF, using chain-of-thought prompting, and overcoming knowledge cut-off challenges.

## Repository Structure

- `week1/`: Contains code and resources for Week 1’s dialogue summarization lab.
- `week2/`: Includes code and resources for Week 2’s fine-tuning lab.
- `week3/`: Provides code and resources for Week 3’s RLHF fine-tuning lab.


